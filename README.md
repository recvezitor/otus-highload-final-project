# otus-highload-final-project

**Итоговый проект**: _Рекомендательная система для высоконагруженного многоканального коммуникационного центра с различными
уровнями нагруженности по количеству операторов_

### Введение

В большинстве проектах связанных с технической поддержкой конечных пользователей возникает проблема оценки качества
работы операторов. Задача усложняется если КЦ поддерживает множество каналов коммуникации, включая голосовые каналы (
телефония), неголосовые (телеграмм, вконтакте, др. мессенджеры), личные кабинеты пользователя, возможно Email канал также
стоит выделить в отдельный поскольку он имеет некоторую специфику, отличающую его от других мессенджеров. Зачастую
требуется получить отчет по типичным SLA метрикам таким как AWT, AHT, QA etc. некоторые метрики нужно получать в режиме
близком к реальному времени real time, отображая метрики на каком-нибудь дашборде доступном для супевайзера, чтобы
вовремя отреагировать например на возросший поток обращений и добавить дополнительных оператров в смену. Стоит отметить,
что нагрузка на БД, которая будет хранить метрики существенно зависит от количества работающих операторов и должна быть
оптимизирована на запись. В то же время получение SLA-метрики в режиме почти real-time также накладывает определенные
ограничения/требования на БД, что потребует компромиссных решений.
В данном проекте предлагается решение для высоконагруженного многоканального КЦ с возможностью выдавать рекомендации для
супервайзера в режиме близком к реальному времени. В зависимости от размеров КЦ предлагается градация на 3 тира. На
каждом тире будет использоваться своя БД: чем выше тир, тем более специфичная БД и тем больше требований к железу и
стоимости решения.

### Оценка нагруженности КЦ

При поверхностном оценке коммуникационных и кол центров (во напиздел) предлагается разделение на 3 тира по количеству
одновременно работающих операторов:

1) 1-60
2) 61-240
3) 241-1000+

Проведем оценку возможной нагрузки на количество генерируемых одним операторов событий связанных с обращением клиента (
открытие, закрытие, перевод и т.д.). Один оператор на голосовом канале физически не может поддерживать более 1го клиента
одновременно. В случае неголосового канала, максимально возможное количество одновременно поддерживаемых клиентов, без
потери качества обслуживания - не более 3х. Соответственно, в качестве верхней оценки возьмём неголосовые каналы. 1 клиент
обычно генерирует не более 3х событий в минуту, соответственно на 1го оператора приходится не более 9 событий в минуту.
Округляя в большую сторону получаем, что 1 оператор генерирует не более 10 событий в минуту, что соответствует 1 событию
в 6 секунд. Соответственно разделение КЦ по нагрузке в терминах RPS преобразуется следующим образом:

1) до 10 событий в секунду
2) до 40 событий в секунду
3) до 150 событий в секунду и выше

При выборе подходящего хранилища событий следует также учитывать, что при продолжительном использовании размер БД растет
стремительно, и необходимая скорость вставки при существенной наполненности может существенно отличаться от скорости в
пустой БД. Оценим объем событий генерируемых каждым тиром КЦ в течении недели, месяца, года:

за неделю:

1) 10 * 60 * 60 * 24 * 7 = 6 048 000
2) 40 * 60 * 60 * 24 * 7 = 24 192 000
3) 150 * 60 * 60 * 24 * 7 = 90 720 000

Очевидно, что даже при самом маленьком тире КЦ наполнение БД происходит очень быстро и соотвественно нужно выбирать
целевую БД, которая не зависит от существующего объема или периодически архивировать собранные события. Учитывая, что
обычно требуется быстрая аналитика по метрикам почти реальном времени, то архиваирование событий старше недели видится
вполне логичной стратегией. Стоит отметить, что не стоит удалять события, а лучше перекладывать в подходящую
аналитическую БД для возможного последующего анализа метрик по более долгоиграющему срезу (недели, месяцы, года)

### Выбор и обоснование БД под каждый тир

На основании сделанных верхнеуровневых оценок предлагается следующий выбор БД для сохранения событий.

1) Ванильный Postgres + потенциально шардирование
2) TimescaleDB
3) ClickHouse

1) При маленьком количестве операторов следует избегать преждевременной оптимизации на не критически важные элементы
   инфраструктуры. Не получить рекомендацию/алерт не так важно как потерять транзакцию с переводом финансов. Поэтому для
   тира 1 с помощью стандартного Postgres, с учетом использования своевременного архивирования исторических событий,
   можно получить желаемую производительность, не вкладываясь в незнакомые инструменты или дополнительное железо.
2) В качестве БД для тира 2 предлагается испольовать плагин/аддон для postgres - timescaledb. Это специализированное для
   хранения timeseries данных расширение Postgres, что автоматически дает знакомый инструмент SQL и безшовную миграцию
   данных при превышении возможностей тира 1. В дополнение к стандартным возможностям реляционных данных timescaledb за
   счет автоматического партицирования (шардирования?) своих гипертаблиц позволяет получать константное время вставки,
   там где стандартный postgres деградирует на порядки величин. Плюс в timescaledb оптимизировано хранение временных
   рядов, что делает его идеальным кандидатом на тир 2.
3) В случае экстремальных значений RPS на вставку требуется использовать специализированный инструмент. Лидером рынка
   здесь является ClickHouse. Благодаря тому, что на предыдущих тирах использовался всем известный стандарт в мире
   реляционных данных - postgres, то миграция с тира 1 или 2 на 3й представляется безпроблемной

### Почему не прометей

Зачастую при упоминании слова "метрики" автоматически всплывает ассоциация со стандартом в мире снятия метрик -
Prometheus. Почему в данном случае он не является целевым решением? Главная причина фундаментальна и связана со способом
получения метрик от целевых сервисов. Прометей использует Pull модель, т.е. он с определенной периодичностью опрашивает
сервисы, которые с фиксированных эндпоинтов отдают метрики, сохраняя в специализированном хранилище. Для отображения
метрик сущетсвует также стандартный инструмент для связки с Прометеем - Графана. К сожалению пул модель, которая
идеально подходит для снятия инфраструктурных метрик (и помогает не захлебнуться под огромным потоком данным от всех
публикующих сервисов), не подходит (или подходит с сущетсвенными ограничениями) для сохранения бизнес метрик. При
сохранении бизнес метрик нам важно точное время события без усреднения или округления, ткие события могут быть очень
нерегулярными. Теоретически мы можем максимально уменьшить время дискредитации (scraping time) прометея, чтобы он
гарантированно не пропустил или не округлил время события. Однако Прометей сохраняет в каждый момент времени не
инкремент, а последнее сумарное значение счетчика (делает он чтобы в случае если метрика не долетела по техническим
причинам, это бы не отразилось в конечном итоге). Поэтому в случае очень разреженного и неравномерного распределения
метрик будет сохраняться чрезмерно большое количество мусорных данных. В случае push модели сохраняется только целевое
событие в произвольный момент времени без необходимости его округлять или приводить к моменту времени сбора данных.
К недостаткам Прометея можно отнести:

- необходимость настраивания долговременного хранилища, зачастую в качестве оного предлагается использовать тот же
  TimescaleDb
- не скалируется горизонтально без дополнитеьных инструментов
- поскольку предполагается выосконагруженным, то нужно либо поднимать дополнительный стенд либо получаем риск падения на
  стенде где снимаются инфраструктурные метрики
- встроенный в Прометей язык запросов PromQL объективно уступает по распространненноси SQL, что является порой ключевой
  харатеристикой при поиске специалистов по поддержке решения.
  Помимо всего Графана не подходит в качестве Пользовательского интерфейса для конечного не технического пользователя, а
  подключения фронта к прометею не является стандартной и тривиальной задачей.
  Prometheus is not intended as a general-purpose time series database and might not be the best choice for high
  cardinality or long-term data storage.

### Другие инструменты

InfluxDb - очень специализированный язык запросов
TODO

### Рекомендации по выбору тира

Для большнинства случаев рекомендуется выбирать тир 2, поскольку он вполне конкуретно способен по скорости вставки с
ClickHouse, но не требует расширение технологического стека за пределы реляционных БД и более лоялен к характеристикам
железа. Тир 1 предлагается выбирать только если есть сверх серьезные внутренние ограничения на расширение техстека,
иногда даже плагин для postgres является проблемой. Также следует учитывать лицензионные ограничения накладываемые
плагином

### Описание SLA метрик

TODO

SLA — это абстрактное понятие, которое строится из множества конкретных метрик и показывает как хорошо настроены
процессы и на сколько пользователи удовлетворены сервисом
Важно чтобы метрики считались для конкретного подразделения. Время работы HelpDesk плохая метрика для Support, потому
что зависит от доступности железа, которое не под контролем оцениваемых
Наша задача как продукта — собрать как можно больше измерений, по которым в последствии можно построить максимально
гибкие метрики

AWT(AverageWaitingTime) = APPEAL_SENT_DISTRIBUTION - APPEAL_APPOINTED   
AHT(AverageHandleTime) = APPEAL_APPOINTED - APPEAL_CLOSED   
QA(QueuedAppeals) = count (APPEAL_NEW || APPEAL_RETURNED)  AND NOT APPEAL_CLOSED
AA(AcceptedAppeals) = count (APPEAL_APPOINTED || APPEAL_CLOSED) AND NOT APPEAL_MISSED   
HA(HandledAppeals) = count (APPEAL_CLOSED)  AND NOT APPEAL_MISSED

### Алерты/Рекомендации

TODO

### Архитектура проекта

#### Компонентная схема

![](img/OTUS-metrics-components.png)

#### Потоки данных

ТУДУ

генератор данных, эталоный, сценарии, случайны, высоконагруженный
толерантность к потере одиночных событий

ТУДУ почему не получится использовать Prometheus заточенный под нефункциональные метрики

major drawback of Prometheus is pull model

Дискретность по времени
downsampling https://last9.io/blog/downsampling-aggregating-metrics-in-prometheus-practical-strategies-to-manage-cardinality-and-query-performance/
долговременное хранение
подключение той же timeseries db
подключение UI а не графаны
not SQL like
https://www.youtube.com/watch?v=W-ouPw944CM

нет долгосрочного хранения - нужно накручивать дополнительные инструменты
хранит только агрегированные метрики, если потом захотим пересчитать в другие метрики - не получится
по умолчанию не скалируется горизонтально без дополнительных инструментов
дополнительная нагрузка на сервис хранения системных метрик, а мы тут со своими бизнесовыми
https://habr.com/ru/articles/441136/

Prometheus is specifically designed for time series data, as its primary focus is on monitoring and alerting based on
the state of infrastructure and applications. It uses a pull-based model, where the Prometheus server scrapes metrics
from the target systems at regular intervals. This model is suitable for monitoring dynamic environments, as it allows
for automatic discovery and monitoring of new instances. However, Prometheus is not intended as a general-purpose time
series database and might not be the best choice for high cardinality or long-term data storage.

TimescaleDB is specifically designed for time series data, making it a natural choice for storing and querying such
data. It provides several advantages for time series data management like horizontal scalability, columnar storage, and
retention policy support. However, TimescaleDB may not be the best choice for all time series use cases. One example
would be if an application requires very high write throughput or real-time analytics, other specialized time series
databases like InfluxDB may be more suitable.

https://www.influxdata.com/comparison/prometheus-vs-timescaledb/

При проектировании тиров стоит учесть постепенно возрастающую потребность - переход от тира к тиру

В первом приближении считаем, что оператор не может

Реализация на 3х уровнях высоконагруженности: ванильный Postgres, Postgres+timescaleDb, ClickHouse

Сравнение с Prometheus, Prometheus+Victoria(or analog)